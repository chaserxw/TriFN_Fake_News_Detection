{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "import re\n",
    "import functools\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News content embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate bag-of-word feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import functools\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\BuzzFeed_real_news_content.csv','r',encoding = 'UTF-8') as buzz_real:\n",
    "    reader = csv.reader(buzz_real)\n",
    "    realContent = [row[2]for row in reader]\n",
    "realContent.remove(realContent[0])\n",
    "\n",
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\BuzzFeed_real_news_content.csv','r',encoding = 'UTF-8') as buzz_real:\n",
    "    reader = csv.reader(buzz_real)\n",
    "    realTitle = [row[0]for row in reader]\n",
    "realTitle.remove(realTitle[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\BuzzFeed_fake_news_content.csv','r',encoding = 'UTF-8') as buzz_fake:\n",
    "    reader = csv.reader(buzz_fake)\n",
    "    content = [row[2]for row in reader]\n",
    "content.remove(content[0])\n",
    "\n",
    "\n",
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\BuzzFeed_fake_news_content.csv','r',encoding = 'UTF-8') as buzz_fake:\n",
    "    reader = csv.reader(buzz_fake)\n",
    "    title = [row[0]for row in reader]\n",
    "title.remove(title[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_patterns = [\n",
    "(r'\\’', '\\''), \n",
    "(r'won\\'t', 'will not'),\n",
    "(r'can\\'t', 'cannot'),\n",
    "(r'i\\'m', 'i am'),\n",
    "(r'ain\\'t', 'is not'),\n",
    "(r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "(r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "(r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "(r'(\\w+)\\'s', '\\g<1> is'),\n",
    "(r'(\\w+)\\'re', '\\g<1> are'),\n",
    "(r'(\\w+)\\'d', '\\g<1> would')]\n",
    "\n",
    "class RegexpReplacer(object):\n",
    "    def __init__(self, patterns=replacement_patterns):\n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            (s, count) = re.subn(pattern, repl, s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacer = RegexpReplacer()\n",
    "contentRevised = []\n",
    "\n",
    "for singleContent in realContent:\n",
    "    singleContentRevised = replacer.replace(singleContent)\n",
    "    contentRevised.append(singleContentRevised)\n",
    "\n",
    "for singleContent in content:\n",
    "    singleContentRevised = replacer.replace(singleContent)\n",
    "    contentRevised.append(singleContentRevised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import nltk.tokenize as tk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = tk.WordPunctTokenizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTitle = realTitle + title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list2 = []\n",
    "i = 1\n",
    "\n",
    "for i in range(len(contentRevised)):\n",
    "    readl = contentRevised[i]\n",
    "    ff = str(readl)\n",
    "    ff=tokenizer.tokenize(ff)\n",
    "    for word in ff:\n",
    "        if word:\n",
    "            word_list2.append(word)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = {}\n",
    "for word in word_list2:\n",
    "    word = word.lower()\n",
    "        # print(word)\n",
    "    word = ''.join(word.split())\n",
    "    if word in tf:\n",
    "        tf[word] += 1\n",
    "    else:\n",
    "        tf[word] = 1\n",
    "#print(tf.keys()) \n",
    "\n",
    "sorted_tf = sorted( tf.items(),key = lambda x:x[1],reverse = True)\n",
    "sorted_tf\n",
    "\n",
    "j = 0\n",
    "sorted_word=[]\n",
    "for j in range(len(sorted_tf)):\n",
    "    sorted_word.append(sorted_tf[j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>and</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>in</th>\n",
       "      <th>that</th>\n",
       "      <th>he</th>\n",
       "      <th>not</th>\n",
       "      <th>...</th>\n",
       "      <th>fashionable</th>\n",
       "      <th>ladies</th>\n",
       "      <th>puffy</th>\n",
       "      <th>hideous</th>\n",
       "      <th>feminist</th>\n",
       "      <th>fervently</th>\n",
       "      <th>gaggle</th>\n",
       "      <th>sociopath</th>\n",
       "      <th>fumbled</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real_1-Webpage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real_10-Webpage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real_11-Webpage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real_12-Webpage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real_13-Webpage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake_88-Webpage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake_89-Webpage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake_9-Webpage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake_90-Webpage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake_91-Webpage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 10144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 the  to  and  is  of  a  in  that  he  not  ...  fashionable  \\\n",
       "Real_1-Webpage     0   0    0   0   0  0   0     0   0    0  ...            0   \n",
       "Real_10-Webpage    0   0    0   0   0  0   0     0   0    0  ...            0   \n",
       "Real_11-Webpage    0   0    0   0   0  0   0     0   0    0  ...            0   \n",
       "Real_12-Webpage    0   0    0   0   0  0   0     0   0    0  ...            0   \n",
       "Real_13-Webpage    0   0    0   0   0  0   0     0   0    0  ...            0   \n",
       "...              ...  ..  ...  ..  .. ..  ..   ...  ..  ...  ...          ...   \n",
       "Fake_88-Webpage    0   0    0   0   0  0   0     0   0    0  ...            0   \n",
       "Fake_89-Webpage    0   0    0   0   0  0   0     0   0    0  ...            0   \n",
       "Fake_9-Webpage     0   0    0   0   0  0   0     0   0    0  ...            0   \n",
       "Fake_90-Webpage    0   0    0   0   0  0   0     0   0    0  ...            0   \n",
       "Fake_91-Webpage    0   0    0   0   0  0   0     0   0    0  ...            0   \n",
       "\n",
       "                 ladies  puffy  hideous  feminist  fervently  gaggle  \\\n",
       "Real_1-Webpage        0      0        0         0          0       0   \n",
       "Real_10-Webpage       0      0        0         0          0       0   \n",
       "Real_11-Webpage       0      0        0         0          0       0   \n",
       "Real_12-Webpage       0      0        0         0          0       0   \n",
       "Real_13-Webpage       0      0        0         0          0       0   \n",
       "...                 ...    ...      ...       ...        ...     ...   \n",
       "Fake_88-Webpage       0      0        0         0          0       0   \n",
       "Fake_89-Webpage       0      0        0         0          0       0   \n",
       "Fake_9-Webpage        0      0        0         0          0       0   \n",
       "Fake_90-Webpage       0      0        0         0          0       0   \n",
       "Fake_91-Webpage       0      0        0         0          0       0   \n",
       "\n",
       "                 sociopath  fumbled  studio  \n",
       "Real_1-Webpage           0        0       0  \n",
       "Real_10-Webpage          0        0       0  \n",
       "Real_11-Webpage          0        0       0  \n",
       "Real_12-Webpage          0        0       0  \n",
       "Real_13-Webpage          0        0       0  \n",
       "...                    ...      ...     ...  \n",
       "Fake_88-Webpage          0        0       0  \n",
       "Fake_89-Webpage          0        0       0  \n",
       "Fake_9-Webpage           0        0       0  \n",
       "Fake_90-Webpage          0        0       0  \n",
       "Fake_91-Webpage          0        0       0  \n",
       "\n",
       "[182 rows x 10144 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_word = pd.DataFrame(0,index=totalTitle, columns=sorted_word)\n",
    "bag_of_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>and</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>in</th>\n",
       "      <th>that</th>\n",
       "      <th>he</th>\n",
       "      <th>not</th>\n",
       "      <th>...</th>\n",
       "      <th>fashionable</th>\n",
       "      <th>ladies</th>\n",
       "      <th>puffy</th>\n",
       "      <th>hideous</th>\n",
       "      <th>feminist</th>\n",
       "      <th>fervently</th>\n",
       "      <th>gaggle</th>\n",
       "      <th>sociopath</th>\n",
       "      <th>fumbled</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real_1-Webpage</th>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real_10-Webpage</th>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real_11-Webpage</th>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real_12-Webpage</th>\n",
       "      <td>92</td>\n",
       "      <td>25</td>\n",
       "      <td>61</td>\n",
       "      <td>34</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real_13-Webpage</th>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake_88-Webpage</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake_89-Webpage</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake_9-Webpage</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake_90-Webpage</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake_91-Webpage</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 10144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 the  to  and  is  of   a  in  that  he  not  ...  \\\n",
       "Real_1-Webpage    42  19   23  17  21  24  22    13   3    7  ...   \n",
       "Real_10-Webpage   31  29   21   7  21  13  21     6   7    2  ...   \n",
       "Real_11-Webpage   22  17    8  13   9  11   8     8   3    6  ...   \n",
       "Real_12-Webpage   92  25   61  34  54  28  36    33   5    8  ...   \n",
       "Real_13-Webpage   38  12   11   5  18   9  11     6   0    3  ...   \n",
       "...              ...  ..  ...  ..  ..  ..  ..   ...  ..  ...  ...   \n",
       "Fake_88-Webpage   25  14   18  15  14   6   9     7   4    9  ...   \n",
       "Fake_89-Webpage   21  10    7   5   7   3   5     6   8    6  ...   \n",
       "Fake_9-Webpage    20   8    6  14   6   8  11    10   1    1  ...   \n",
       "Fake_90-Webpage    2   2    5   4   1   5   2     1   0    2  ...   \n",
       "Fake_91-Webpage   16   6    5  17  12  14   5    12  27    6  ...   \n",
       "\n",
       "                 fashionable  ladies  puffy  hideous  feminist  fervently  \\\n",
       "Real_1-Webpage             0       0      0        0         0          0   \n",
       "Real_10-Webpage            0       0      0        0         0          0   \n",
       "Real_11-Webpage            0       0      0        0         0          0   \n",
       "Real_12-Webpage            0       0      0        0         0          0   \n",
       "Real_13-Webpage            0       0      0        0         0          0   \n",
       "...                      ...     ...    ...      ...       ...        ...   \n",
       "Fake_88-Webpage            0       0      0        0         0          0   \n",
       "Fake_89-Webpage            0       0      0        0         0          0   \n",
       "Fake_9-Webpage             0       0      0        0         0          0   \n",
       "Fake_90-Webpage            0       0      0        0         0          0   \n",
       "Fake_91-Webpage            1       1      1        1         1          1   \n",
       "\n",
       "                 gaggle  sociopath  fumbled  studio  \n",
       "Real_1-Webpage        0          0        0       0  \n",
       "Real_10-Webpage       0          0        0       0  \n",
       "Real_11-Webpage       0          0        0       0  \n",
       "Real_12-Webpage       0          0        0       0  \n",
       "Real_13-Webpage       0          0        0       0  \n",
       "...                 ...        ...      ...     ...  \n",
       "Fake_88-Webpage       0          0        0       0  \n",
       "Fake_89-Webpage       0          0        0       0  \n",
       "Fake_9-Webpage        0          0        0       0  \n",
       "Fake_90-Webpage       0          0        0       0  \n",
       "Fake_91-Webpage       1          1        1       1  \n",
       "\n",
       "[182 rows x 10144 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "contentList = {}\n",
    "col = 0\n",
    "\n",
    "for singleContent in contentRevised:\n",
    "    singleContent = singleContent.lower()  \n",
    "    singleContentClean = tokenizer.tokenize(str(singleContent))\n",
    "    \n",
    "    #words = singleContentClean.split()\n",
    "    c = collections.Counter(singleContentClean)   \n",
    "    items = c.most_common(len(c)) \n",
    "    #print(items)\n",
    "    \n",
    "    for i in range (len(items)):\n",
    "        word,count = items[i]\n",
    "        bag_of_word.loc[totalTitle[col],word]=count\n",
    "\n",
    "    col = col + 1\n",
    "    \n",
    "\n",
    "bag_of_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### refer to https://blog.csdn.net/jeffery0207/article/details/84348117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42, 19, 23, ...,  0,  0,  0],\n",
       "       [31, 29, 21, ...,  0,  0,  0],\n",
       "       [22, 17,  8, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [20,  8,  6, ...,  0,  0,  0],\n",
       "       [ 2,  2,  5, ...,  0,  0,  0],\n",
       "       [16,  6,  5, ...,  1,  1,  1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_news = np.array(bag_of_word)\n",
    "X_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\X.npy',X_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=10, init='random', random_state=0)\n",
    "D_news = model.fit_transform(X_news) \n",
    "V_T_news = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10144)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_T_news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:UTF-8\n",
    "import scipy.io as scio\n",
    "\n",
    "data = scio.loadmat(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\BuzzFeedUserFeature.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=10, init='random', random_state=0)\n",
    "U_user = model.fit_transform(data[\"X\"]) \n",
    "V_T_user = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15257, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01270652, 0.00928831, 0.        , ..., 0.08953801, 0.        ,\n",
       "        0.06489793],\n",
       "       [0.00544227, 0.        , 0.        , ..., 0.0702968 , 0.02678174,\n",
       "        0.        ],\n",
       "       [0.        , 0.00379981, 0.15800272, ..., 0.        , 0.00067577,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00777302, 0.03950091, 0.        , ..., 0.04497584, 0.05883137,\n",
       "        0.        ],\n",
       "       [0.02714792, 0.03801681, 0.        , ..., 0.04326348, 0.        ,\n",
       "        0.        ],\n",
       "       [0.01955202, 0.        , 0.        , ..., 0.01463868, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 109626)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_T_user.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-News Interaction Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_news_interaction_path = r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data/BuzzFeedNewsUser.txt'\n",
    "with open(user_news_interaction_path, 'r') as ff:\n",
    "    lines = ff.readlines()\n",
    "user_list = set()\n",
    "news_list = set()\n",
    "for line in lines:\n",
    "    split = line.split('\\t')\n",
    "    news, user, times = split[0], split[1], split[2]\n",
    "    news_list.add(news)\n",
    "    user_list.add(user)\n",
    "news_list = list(news_list)\n",
    "user_list = list(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list.sort()\n",
    "user_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be replace by real data of the same shape\n",
    "W = tf.random.uniform([m, n], minval=0, maxval=10, dtype=tf.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be replace by real data of the same shape\n",
    "c = tf.random.normal([1, m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((91, 10), (15257, 10))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_news.shape,U_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-c4fc102b6baa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m w = tf.get_variable(initializer=tf.abs(tf.random_normal((data.shape[0], 2))), \n\u001b[0m\u001b[0;32m      2\u001b[0m                     constraint=lambda p: tf.maximum(0., p))\n\u001b[0;32m      3\u001b[0m h = tf.get_variable(initializer=tf.abs(tf.random_normal((2, data.shape[1]))), \n\u001b[0;32m      4\u001b[0m                     constraint=lambda p: tf.maximum(0., p))\n\u001b[0;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "w = tf.get_variable(initializer=tf.abs(tf.random_normal((data.shape[0], 2))), \n",
    "                    constraint=lambda p: tf.maximum(0., p))\n",
    "h = tf.get_variable(initializer=tf.abs(tf.random_normal((2, data.shape[1]))), \n",
    "                    constraint=lambda p: tf.maximum(0., p))\n",
    "loss = tf.sqrt(tf.reduce_sum(tf.squared_difference(x, tf.matmul(w, h))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (m,n,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publisher-News Relation Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider only the following three partisan and we may not obtain the partisan lables for all publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_pub = []\n",
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\partisan\\left.txt','r',encoding = 'UTF-8') as left:\n",
    "    lines = left.readlines()\n",
    "    for line in lines:\n",
    "        line = line.split('(')\n",
    "        if len(line)> 1:\n",
    "            single_line = line[1].split(')')\n",
    "            left_pub.append(single_line[0])\n",
    "        \n",
    "#left_pub\n",
    "#-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_pub = []\n",
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\partisan\\right.txt','r',encoding = 'UTF-8') as right:\n",
    "    lines = right.readlines()\n",
    "    for line in lines:\n",
    "        line = line.split('(')\n",
    "        if len(line)> 1:\n",
    "            single_line = line[1].split(')')\n",
    "            right_pub.append(single_line[0])\n",
    "        \n",
    "#right_pub\n",
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_biased_pub = []\n",
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\partisan\\least-biased.txt','r',encoding = 'UTF-8') as least_biased:\n",
    "    lines = least_biased.readlines()\n",
    "    for line in lines:\n",
    "        line = line.split('(')\n",
    "        if len(line)> 1:\n",
    "            single_line = line[1].split(')')\n",
    "            least_biased_pub.append(single_line[0])\n",
    "            \n",
    "#least_biased_pub\n",
    "#0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate publisher-news publishing matrix B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://www.addictinginfo.org', 'http://eaglerising.com', 'http://eaglerising.com', 'http://www.addictinginfo.org', 'http://www.proudcons.com', 'http://allenwestrepublic.com', 'http://eaglerising.com', 'http://100percentfedup.com', 'http://eaglerising.com', 'http://conservativebyte.com', 'https://goo.gl', 'http://usherald.com', 'http://eaglerising.com', 'http://theblacksphere.net', '', 'http://winningdemocrats.com', 'http://usherald.com', 'http://allenwestrepublic.com', 'http://eaglerising.com', 'http://eaglerising.com', 'http://eaglerising.com', '', 'http://eaglerising.com', '', '', 'http://freedomdaily.com', 'http://author.groopspeak.com', '', 'https://goo.gl', 'http://freedomdaily.com', 'http://freedomdaily.com', 'http://freedomdaily.com', 'http://www.proudcons.com', 'http://100percentfedup.com', 'http://freedomdaily.com', 'http://freedomdaily.com', 'http://freedomdaily.com', 'http://freedomdaily.com', 'http://www.addictinginfo.org', 'http://freedomdaily.com', 'http://freedomdaily.com', 'http://freedomdaily.com', 'http://freedomdaily.com', 'http://freedomdaily.com', 'http://clashdaily.com', 'https://goo.gl', 'http://freedomdaily.com', '', '', 'http://freedomdaily.com', 'http://author.addictinginfo.org', 'http://freedomdaily.com', 'http://www.yesimright.com', 'http://occupydemocrats.com', 'http://occupydemocrats.com', 'http://eaglerising.com', 'http://occupydemocrats.com', 'http://occupydemocrats.com', '', 'http://occupydemocrats.com', 'http://occupydemocrats.com', 'http://rightwingnews.com', 'http://winningdemocrats.com', 'http://rightwingnews.com', 'http://rightwingnews.com', 'http://rightwingnews.com', 'http://eaglerising.com', 'http://rightwingnews.com', 'http://www.thepoliticalinsider.com', 'http://www.chicksontheright.com', 'http://rightwingnews.com', 'http://rightwingnews.com', 'http://rightwingnews.com', 'http://addictinginfo.org', 'http://conservativetribune.com', 'https://ihavethetruth.com', 'http://rightwingnews.com', 'http://theblacksphere.net', 'https://ihavethetruth.com', 'http://rightwingnews.com', 'http://www.thepoliticalinsider.com', 'http://rightwingnews.com', 'http://rightwingnews.com', 'http://rightwingnews.com', 'http://rightwingnews.com', 'http://rightwingnews.com', 'http://rightwingnews.com', 'http://conservativetribune.com', 'http://clashdaily.com', 'http://www.thepoliticalinsider.com', 'http://rightwingnews.com']\n"
     ]
    }
   ],
   "source": [
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\BuzzFeed_fake_news_content.csv','r',encoding = 'UTF-8') as buzz_fake:\n",
    "    reader = csv.reader(buzz_fake)\n",
    "    source_buzz_fake = [row[6]for row in reader]\n",
    "source_buzz_fake.remove(source_buzz_fake[0])\n",
    "print(source_buzz_fake)\n",
    "\n",
    "for source in source_buzz_fake:\n",
    "    if source not in publisher:\n",
    "        if len(source) > 0:\n",
    "            publisher.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\BuzzFeed_real_news_content.csv','r',encoding = 'UTF-8') as buzz_real:\n",
    "    reader = csv.reader(buzz_real)\n",
    "    source_buzz_real = [row[6]for row in reader]\n",
    "source_buzz_real.remove(source_buzz_real[0])\n",
    "#print(source_buzz_real)\n",
    "\n",
    "for source in source_buzz_real:\n",
    "    if source not in publisher:\n",
    "        if len(source) > 0:\n",
    "            publisher.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore politi\n",
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\PolitiFact_fake_news_content.csv','r',encoding = 'UTF-8') as politi_fake:\n",
    "    reader = csv.reader(politi_fake) \n",
    "    source_politi_fake = [row[6]for row in reader]\n",
    "source_politi_fake.remove(source_politi_fake[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore politic\n",
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\PolitiFact_real_news_content.csv','r',encoding = 'UTF-8') as politi_real:\n",
    "    reader = csv.reader(politi_real)\n",
    "    source_politi_real = [row[6]for row in reader]\n",
    "source_politi_real.remove(source_politi_real[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "publishers = []\n",
    "for single_publisher in publisher:\n",
    "    temp = single_publisher.split('//')\n",
    "    publishers.append(temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.addictinginfo.org',\n",
       " 'http://eaglerising.com',\n",
       " 'http://www.proudcons.com',\n",
       " 'http://allenwestrepublic.com',\n",
       " 'http://100percentfedup.com',\n",
       " 'http://conservativebyte.com',\n",
       " 'https://goo.gl',\n",
       " 'http://usherald.com',\n",
       " 'http://theblacksphere.net',\n",
       " 'http://winningdemocrats.com',\n",
       " 'http://freedomdaily.com',\n",
       " 'http://author.groopspeak.com',\n",
       " 'http://clashdaily.com',\n",
       " 'http://author.addictinginfo.org',\n",
       " 'http://www.yesimright.com',\n",
       " 'http://occupydemocrats.com',\n",
       " 'http://rightwingnews.com',\n",
       " 'http://www.thepoliticalinsider.com',\n",
       " 'http://www.chicksontheright.com',\n",
       " 'http://addictinginfo.org',\n",
       " 'http://conservativetribune.com',\n",
       " 'https://ihavethetruth.com',\n",
       " 'http://abcn.ws',\n",
       " 'http://politi.co',\n",
       " 'http://cnn.it',\n",
       " 'http://www.opposingviews.com',\n",
       " 'http://www.ifyouonlynews.com',\n",
       " 'https://www.washingtonpost.com']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.addictinginfo.org',\n",
       " 'eaglerising.com',\n",
       " 'www.proudcons.com',\n",
       " 'allenwestrepublic.com',\n",
       " '100percentfedup.com',\n",
       " 'conservativebyte.com',\n",
       " 'goo.gl',\n",
       " 'usherald.com',\n",
       " 'theblacksphere.net',\n",
       " 'winningdemocrats.com',\n",
       " 'freedomdaily.com',\n",
       " 'author.groopspeak.com',\n",
       " 'clashdaily.com',\n",
       " 'author.addictinginfo.org',\n",
       " 'www.yesimright.com',\n",
       " 'occupydemocrats.com',\n",
       " 'rightwingnews.com',\n",
       " 'www.thepoliticalinsider.com',\n",
       " 'www.chicksontheright.com',\n",
       " 'addictinginfo.org',\n",
       " 'conservativetribune.com',\n",
       " 'ihavethetruth.com',\n",
       " 'abcn.ws',\n",
       " 'politi.co',\n",
       " 'cnn.it',\n",
       " 'www.opposingviews.com',\n",
       " 'www.ifyouonlynews.com',\n",
       " 'www.washingtonpost.com']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先real再fake\n",
    "newsIndex = []\n",
    "\n",
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\BuzzFeedNews.txt','r',encoding = 'UTF-8') as news_index:\n",
    "    lines = news_index.readlines()\n",
    "    for line in lines:\n",
    "        line = line.split('_')\n",
    "        newsIndex.append(int(line[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake news title\n",
    "for singleTitle in title:\n",
    "    temp_single = singleTitle.split('_')\n",
    "    single = temp_single[1].split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real news title\n",
    "for singleTitle in realTitle:\n",
    "    temp_single = singleTitle.split('_')\n",
    "    single = temp_single[1].split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.zeros((28,182))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_row=[]\n",
    "user_col=[]\n",
    "\n",
    "#fake\n",
    "for i in range(0,91):\n",
    "    #print(source_buzz_fake[i])\n",
    "    if source_buzz_fake[i] in publisher:\n",
    "        row_index = publisher.index(source_buzz_fake[i])\n",
    "        #print(source_buzz_fake[i])\n",
    "        #print(row_index) \n",
    "        \n",
    "        singleTitle = title[i]\n",
    "        #print(singleTitle)\n",
    "        temp_single = singleTitle.split('_')\n",
    "        #print(temp_single)\n",
    "        single = temp_single[1].split('-')\n",
    "        #print(single[0])\n",
    "        col_index = newsIndex.index(int(single[0]))+91      \n",
    "        B[row_index,col_index] = 1\n",
    "\n",
    "#real\n",
    "for i in range(0,91):\n",
    "    #print(source_buzz_fake[i])\n",
    "    if source_buzz_real[i] in publisher:\n",
    "        row_index = publisher.index(source_buzz_real[i])\n",
    "        #print(source_buzz_fake[i])\n",
    "        #print(row_index) \n",
    "        \n",
    "        singleTitle = realTitle[i]\n",
    "        #print(singleTitle)\n",
    "        temp_single = singleTitle.split('_')\n",
    "        #print(temp_single)\n",
    "        single = temp_single[1].split('-')\n",
    "        #print(single[0])\n",
    "        col_index = newsIndex.index(int(single[0]))    \n",
    "        B[row_index,col_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\B.npy',B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate publisher partisan bias lable vectors o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 1,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 1,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for pub in publishers:\n",
    "    if pub in left_pub:\n",
    "        o.append(-1)\n",
    "    if pub in right_pub:\n",
    "        o.append(1)\n",
    "    if pub in least_biased_pub:\n",
    "        o.append(0)\n",
    "    else:\n",
    "        o.append(None)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.addictinginfo.org',\n",
       " 'eaglerising.com',\n",
       " 'www.proudcons.com',\n",
       " 'allenwestrepublic.com',\n",
       " '100percentfedup.com',\n",
       " 'conservativebyte.com',\n",
       " 'goo.gl',\n",
       " 'usherald.com',\n",
       " 'theblacksphere.net',\n",
       " 'winningdemocrats.com',\n",
       " 'freedomdaily.com',\n",
       " 'author.groopspeak.com',\n",
       " 'clashdaily.com',\n",
       " 'author.addictinginfo.org',\n",
       " 'www.yesimright.com',\n",
       " 'occupydemocrats.com',\n",
       " 'rightwingnews.com',\n",
       " 'www.thepoliticalinsider.com',\n",
       " 'www.chicksontheright.com',\n",
       " 'addictinginfo.org',\n",
       " 'conservativetribune.com',\n",
       " 'ihavethetruth.com',\n",
       " 'abcn.ws',\n",
       " 'politi.co',\n",
       " 'cnn.it',\n",
       " 'www.opposingviews.com',\n",
       " 'www.ifyouonlynews.com',\n",
       " 'www.washingtonpost.com']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publishers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate user-user interaction matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((15257,15257)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "A\n",
    "A=A.astype( np.uint8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\BuzzFeedUserUser.txt','r',encoding = 'UTF-8') as user_interact:\n",
    "    lines = user_interact.readlines()\n",
    "    for line in lines:\n",
    "        line = line.split() \n",
    "        A[int(line[0])-1,int(line[1])-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[47,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[800,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\A.npy',A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Generate user-news interaction matrix W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.zeros((15257,182))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row:user\n",
    "#col:news\n",
    "with open(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\BuzzFeedNewsUser.txt','r',encoding = 'UTF-8') as user_news:\n",
    "    lines = user_news.readlines()\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        user = line[1]\n",
    "        news = line[0]\n",
    "        W[int(user)-1,int(news)-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'C:\\Users\\学汪\\Desktop\\summner research\\kaggle_data\\W.npy',W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate publisher partisan bias lable vectors o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
